#Human Activity Recognition Using Smartphones

### Course Project
### Getting and cleaning Data, Coursera
### Nick Burns, 2014

-------------------------------------------------------------------------------

## Background

The purpose of this project is to extract and clean a raw dataset, producing
a tidy dataset for further analysis. The final, tidy dataset (human_activity_data.txt) is described below:

## Human Activity Data

The final dataset, human_activity_data.txt, is made up of 180 observations each with 68 variables.
The observations are of 30 subjects and are a summary of the data collected by Reyes-Ortiz, Anguita, Ghio and Oneto (described below).

The structure of human_activity_data.txt is given below:

```{r echo=TRUE}
human_activity_data <- read.table("human_activity_data.txt")

str(human_activity_data)
```


The variables within human_activity_data.txt can be summarised:

```{r echo=TRUE}
summary(human_activity_data)
```

## Source Data
The raw data is from a study into Human Activity Recognition using Smartphones, which is part of an emerging field of
study into *wearable computing*. The raw dataset is from the **UCI Machine 
Learning Repository** (http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones),
where a full description of the experiment and dataset are available. Below is a 
brief description of the raw dataset, as described by Reyes-Ortiz, Anguita, Ghio and Oneto
at the above website:

### Description of the Dataset
The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data. 

### Attribute Information
For each record in the dataset it is provided: 
- Triaxial acceleration from the accelerometer (total acceleration) and the estimated body acceleration. 
- Triaxial Angular velocity from the gyroscope. 
- A 561-feature vector with time and frequency domain variables. 
- Its activity label. 
- An identifier of the subject who carried out the experiment.

(Reyes-Ortiz, Anguita, Ghio and Oneto. UCI Machine Learning Repository. http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones, (accessed 21 June 2014))



-------------------------------------------------------------------------------

## Preparation

Load required libraries
```{r echo=TRUE}
library(sqldf)
library(plyr)
```

Set the working directory and extract the raw data
```{r echo=TRUE}
setwd("C:/DataSciToolkit/DataScienceToolkit/GetCleanData/CleaningData")
unzip("getdata-projectfiles-UCI HAR Dataset.zip")
```

-------------------------------------------------------------------------------

## [1, 2] Merge the Test and Training datasets

The goal is to produce a single, tidy dataset with the average of each variable for each activity and each subject.
For the purposes of this assignment, we do not distinguish between the test and the training sets, so we will
combine these into one superset.

We need to combine 3 set of files to create the superset. The files are described below:

**X_train.txt, X_test.txt  (OBSERVATIONS) **  
These files hold the actual observations. There are 7352 observations, each of which is made up of 561 feature values.
The feature values are described in the file, **features.txt**, and are ordered as presented in this file.

**y_train.txt, y_test.txt  (ACTIVITIES)  **    
The observations were recorded while the subjects were performing certain activities. These activities are described
in the file, **activity_labels.txt**. For each observation in **X_train.txt, X_test.txt**, there is a corresponding
integer value, {1, 2, .., 6}, in **y_train.txt, y_test.txt**. These integer values map an activity name to each 
observation.

**subject_train.txt, subject_test.txt  (SUBJECTS)  **  
Like the mapping of ACTIVITIES to OBSERVATIONS, these subject files contain an series of 7352 integers that correspond
to a given subject. In this study, the subjects are only identified by this unique and anonymous SubjectID which we will
also use in the creation of our superset.

Below, the OBSERVATIONS, ACTIVITIES and SubJECTS are mapped onto one another to produce a superset containing one row
for each mapping of {SubjectID, ActivityName, OBSERVATIONS}.  
NOTE: that the OBSERVATIONS ar themselves a vector of length *n*, and that each element will be named according to the name
in the file, **features.txt**.  

```{r echo=TRUE}
# read in the feature labels and the observations
lbl_features <- read.table("./UCI HAR Dataset/features.txt")
observations <- rbind(  read.table("./UCI HAR Dataset/test/X_test.txt")
                      , read.table("./UCI HAR Dataset/train/X_train.txt") )

# read in the activity labels and the activities
lbl_activity <- read.table("./UCI HAR Dataset/activity_labels.txt")
activities   <- rbind(  read.table("./UCI HAR Dataset/test/y_test.txt")
                      , read.table("./UCI HAR Dataset/train/y_train.txt") )

# read in the subjectIDs
subjects <- rbind(  read.table("./UCI HAR Dataset/test/subject_test.txt")
                  , read.table("./UCI HAR Dataset/train/subject_train.txt") )
```

With the raw data read in, we now want to subset the observations to only those features related to mean() and std()
```{r echo=TRUE}
# extract index of relevant features
names(lbl_features) <- c("featureID", "label")
names(lbl_activity) <- c("activityID", "label")

idx_features <- sqldf("SELECT featureID, label
                       FROM lbl_features
                       WHERE label LIKE '%mean()%'
                          OR label LIKE '%std()%'
                      ")
# subset the observations to only include those of interest 
# i.e. select all rows from observations, but only columns from idx_features
observations <- observations[, idx_features$featureID]

# finally, apply the feature names to observations
names(observations) <- idx_features$label
```

Now that the OBSERVATIONS are suitably collated, we need to append the ACTIVITIES and SUBJECTS to create the superset

```{r echo=TRUE}
# first we will column bind the activities and subjects to the observations
superset <- data.frame(subjects, activities, observations)
names(superset) <- c("SubjectID", "Activity", names(observations))

# now we will replace the activity integers with their corresponding names
superset$Activity <- sqldf("  SELECT lblA.label
                              FROM superset as sup
                                JOIN lbl_activity as lblA
                              WHERE sup.Activity = lblA.activityID
                          ")
```

Finally, we are to create a new tidy dataset that is the average of each activity for each subject.

```{r echo=TRUE}
# for the sake of making this easy, I am going to recreate the superset, without the ActivityLabel
# I found when using the sqldf package, there was a datatype error where the Activity column was
# perceived as a data.frame() and therefore invalid.

rm(superset)
superset <- data.frame(subjects, activities, observations)
names(superset) <- c("SubjectID", "Activity", names(observations))

# now group the data by SubjectID and Activity and calculate the mean for all observations
tidy <- ddply(    superset
                , c("SubjectID", "Activity")
                , function(q) sapply(q[, c(3:68)], mean)
             )
# I tried so many things before I found ddply. This is amazing, and quick!

# Finally, for clarity I will replace the ActivityIDs with ActivityLabels once more
tmp <- sqldf("  SELECT lblA.label
                FROM tidy as t
                  JOIN lbl_activity as lblA
                WHERE t.Activity = lblA.activityID
            ")

tidy$Activity <- as.character(tmp[[1]])

# and lastly, write out the results
write.table(tidy, "human_activity_data.txt")

```

I spent so long on this final part. Probably spent 4 hours on the whole assignment, with 3 of them being on this last question. It took me a very very long time to figure out how to calculate the averages across the columns. 
- colMeans returned a data frame that was oriented the wrong way. 
- Writing a sqldf query was not practical due to the field names and the numebr of them
- had some wierd issues with the ActivityNames, they made life difficult which is why I reverted to using the integers
- finally hit upon ddply.

I have been avoiding some of the higher-level libraries like plyr because I want to really wrap my head around the more basic building blocks of R. But in this case, it was dead easy - once I stumbled on it, I had the solution in 5 minutes. Have learned a valuable lesson: *don't be too stubborn!*. 
